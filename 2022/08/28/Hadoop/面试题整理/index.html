<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Hadoop各种概念介绍 | The Xiang Blog</title><meta name="keywords" content="MR,HDFS,Yarn"><meta name="author" content="Xiang Liu"><meta name="copyright" content="Xiang Liu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="介绍了Hadoop中的各种概念">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop各种概念介绍">
<meta property="og:url" content="http://example.com/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/index.html">
<meta property="og:site_name" content="The Xiang Blog">
<meta property="og:description" content="介绍了Hadoop中的各种概念">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/image/bg.jpg">
<meta property="article:published_time" content="2022-08-28T02:04:51.752Z">
<meta property="article:modified_time" content="2022-08-28T12:12:15.256Z">
<meta property="article:author" content="Xiang Liu">
<meta property="article:tag" content="MR">
<meta property="article:tag" content="HDFS">
<meta property="article:tag" content="Yarn">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/image/bg.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hadoop各种概念介绍',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2022-08-28 20:12:15'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./image/title.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">88</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 总览</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/../image/bg.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">The Xiang Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 总览</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Hadoop各种概念介绍</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-28T02:04:51.752Z" title="发表于 2022-08-28 10:04:51">2022-08-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-08-28T12:12:15.256Z" title="更新于 2022-08-28 20:12:15">2022-08-28</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Hadoop/">Hadoop</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">10.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>33分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Hadoop各种概念介绍"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="1-Hadoop的优势是什么？"><a href="#1-Hadoop的优势是什么？" class="headerlink" title="1.Hadoop的优势是什么？"></a>1.Hadoop的优势是什么？</h2><ol>
<li>高可靠性：Hadoop底层会维度多个数据副本，即使Hadoop某个存储出现故障，也不会导致数据的丢失</li>
<li>高扩展性：在集群之间分配任务数据，可以十分方便的扩展数以千计的节点</li>
<li>高效性：在MR的思想下，Hadoop处理问题的策略是并行的，可以加快任务处理的速度</li>
<li>高容错性：能够自动把失败的任务重新分配</li>
</ol>
<h2 id="2-Hadoop1版本和Hadoop2版本的区别？"><a href="#2-Hadoop1版本和Hadoop2版本的区别？" class="headerlink" title="2.Hadoop1版本和Hadoop2版本的区别？"></a>2.Hadoop1版本和Hadoop2版本的区别？</h2><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661652672746.png" alt="1661652672746"></p>
<p>在Hadoop1版本的时候，计算和资源调度都是由MR来实现，耦合性太高，在Hadoop2版本增加了Yarn资源调度模块，MR仅仅负责计算</p>
<h2 id="3-HDFS架构简述？"><a href="#3-HDFS架构简述？" class="headerlink" title="3.HDFS架构简述？"></a>3.HDFS架构简述？</h2><ol>
<li>NameNode：存储文件的元数据信息，如文件名，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表，还有每个文件所在的块列表和块所在的DateNode等等</li>
<li>DataNode: 在本地文件系统存储文件快数据，以及块数据的校验和</li>
<li>Secondary NameNode：每隔一段时间就会对NameNode元数据进行备份，但是是冷备份，治标不治本。</li>
</ol>
<h2 id="4-Yarn架构简述？"><a href="#4-Yarn架构简述？" class="headerlink" title="4.Yarn架构简述？"></a>4.Yarn架构简述？</h2><ol>
<li>ResourceManager: 处理客户端请求、监控NodeManager、启动或者监控ApplicationMaster、资源的分配与调度</li>
<li>NodeManager: 管理单个节点上的资源、处理来自ResourceManager的命令、处理来自ApplicationMaster的命令</li>
<li>ApplicationMaster：负责数据的切分、为应用程序申请资源并分配给内部的任务、任务的监控与容错</li>
<li>Container：他是YARN的资源抽象，封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等等</li>
</ol>
<h2 id="5-为什么HDFS文件块设置为128MB？"><a href="#5-为什么HDFS文件块设置为128MB？" class="headerlink" title="5.为什么HDFS文件块设置为128MB？"></a>5.为什么HDFS文件块设置为128MB？</h2><p><a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=HDFS&spm=1001.2101.3001.7020">HDFS</a>中的文件在物理上是分块存储（<code>Block</code>），块的大小可以通过配置参数(<code>dfs.blocksize</code>）来规定，默认大小在Hadoop2.x版本中是128M，老版本中是64M。</p>
<p>默认为128M的原因，基于最佳传输损耗理论！</p>
<p>不论对磁盘的文件进行读还是写，都需要先进行寻址！</p>
<p>最佳传输损耗理论：在一次传输中，寻址时间占用总传输时间的1%时，本次传输的损耗最小，为最佳性价比传输！<br>目前硬件的发展条件，普通磁盘写的速率大概为100M&#x2F;S, 寻址时间一般为10ms!</p>
<p><code>10ms / 1% = 1s</code><br><code>1s * 100M/S=100M</code></p>
<p>块在传输时，<code>每64K还需要校验一次</code>，因此块大小，必须为<code>2的n次方</code>，最接近100M的就是128M！</p>
<p><strong>为什么块的大小不能设置太小，也不能设置太大？</strong></p>
<ol>
<li><p>如果块设置过大，</p>
<p> 一方面，从磁盘传输数据的时间会明显大于寻址时间，导致程序在处理这块数据时，变得非常慢；</p>
<p> 另一方面，mapreduce中的map任务通常一次只处理一个块中的数据，如果块过大运行速度也会很慢。</p>
</li>
<li><p>如果块设置过小，</p>
<p>一方面存放大量小文件会占用NameNode中大量内存来存储元数据，而NameNode的内存是有限的，不可取；</p>
<p>另一方面文件块过小，寻址时间增大，导致程序一直在找block的开始位置。</p>
</li>
</ol>
<p>因而，块适当设置大一些，减少寻址时间，那么传输一个由多个块组成的文件的时间主要取决于磁盘的传输速率。</p>
<h2 id="6-HDFS的写流程"><a href="#6-HDFS的写流程" class="headerlink" title="6.HDFS的写流程"></a>6.HDFS的写流程</h2><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661661770326.png" alt="1661661770326"></p>
<ol>
<li>客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。</li>
<li>NameNode返回是否可以上传。</li>
<li>客户端请求第一个 Block上传到哪几个DataNode服务器上。</li>
<li>NameNode返回3个DataNode节点，分别为dn1、dn2、dn3。</li>
<li>客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。</li>
<li>dn1、dn2、dn3逐级应答客户端。</li>
<li>客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。</li>
<li>当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）。</li>
</ol>
<h3 id="6-1-节点距离计算？"><a href="#6-1-节点距离计算？" class="headerlink" title="6.1 节点距离计算？"></a>6.1 节点距离计算？</h3><p>在HDFS写数据的过程中，NameNode会选择距离待上传数据最近距离的DataNode接收数据。那么这个最近距离怎么计算呢？</p>
<p>节点距离：两个节点到达最近的共同祖先的距离总和。</p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661661934358.png" alt="1661661934358"></p>
<h3 id="6-2Hadoop副本节点选择策略"><a href="#6-2Hadoop副本节点选择策略" class="headerlink" title="6.2Hadoop副本节点选择策略"></a>6.2Hadoop副本节点选择策略</h3><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661662094057.png" alt="1661662094057"></p>
<h2 id="7-HDFS读数据流程"><a href="#7-HDFS读数据流程" class="headerlink" title="7.HDFS读数据流程"></a>7.HDFS读数据流程</h2><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661662132533.png" alt="1661662132533"></p>
<ol>
<li>客户端通过DistributedFileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。</li>
<li>挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。</li>
<li>DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）。</li>
<li>客户端以Packet为单位接收，先在本地缓存，然后写入目标文件。</li>
</ol>
<h2 id="8-NameNode和SecondaryNameNode"><a href="#8-NameNode和SecondaryNameNode" class="headerlink" title="8.NameNode和SecondaryNameNode"></a>8.NameNode和SecondaryNameNode</h2><h3 id="8-1-NN和2NN的工作机制"><a href="#8-1-NN和2NN的工作机制" class="headerlink" title="8.1 NN和2NN的工作机制"></a>8.1 NN和2NN的工作机制</h3><p>​	思考：NameNode中的元数据存储在哪里？</p>
<p>​	首先，我们做个假设，如果存储在NameNode节点的磁盘中，因为经常需要进行随机访问，还有响应客户请求，必然是效率过低。因此，元数据需要存放在内存中。但如果只存在内存中，一旦断电，元数据丢失，整个集群就无法工作了。因此产生在磁盘中备份元数据的FsImage。</p>
<p>​	这样又会带来新的问题，当在内存中的元数据更新时，如果同时更新FsImage，就会导致效率过低，但如果不更新，就会发生一致性问题，一旦NameNode节点断电，就会产生数据丢失。因此，引入Edits文件(只进行追加操作，效率很高)。每当元数据有更新或者添加元数据时，修改内存中的元数据并追加到Edits中。这样，一旦NameNode节点断电，可以通过FsImage和Edits的合并，合成元数据。</p>
<p>​	但是，如果长时间添加数据到Edits中，会导致该文件数据过大，效率降低，而且一旦断电，恢复元数据需要的时间过长。因此，需要定期进行FsImage和Edits的合并，如果这个操作由NameNode节点完成，又会效率过低。因此，引入一个新的节点SecondaryNamenode，专门用于FsImage和Edits的合并。</p>
<hr>
<p><strong>NameNode工作机制</strong></p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661669014177.png" alt="1661669014177"></p>
<p><strong>第一阶段：NameNode启动</strong></p>
<ol>
<li>第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。</li>
<li>客户端对元数据进行增删改的请求。</li>
<li>NameNode记录操作日志，更新滚动日志。</li>
<li>NameNode在内存中对元数据进行增删改。</li>
</ol>
<p><strong>第二阶段：SecondaryNameNode</strong></p>
<ol>
<li>Secondary NameNode询问NameNode是否需要CheckPoint。直接带回NameNode是否检查结果。</li>
<li>Secondary NameNode请求执行CheckPoint。</li>
<li>NameNode滚动正在写的Edits日志。</li>
<li>将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode。</li>
<li>Secondary NameNode加载编辑日志和镜像文件到内存，并合并。</li>
<li>生成新的镜像文件fsimage.chkpoint。</li>
<li>拷贝fsimage.chkpoint到NameNode。</li>
<li>NameNode将fsimage.chkpoint重新命名成fsimage。</li>
</ol>
<p><strong>NN和2NN的工作机制详解：</strong></p>
<p>Fsimage：NameNode内存中元数据序列化后形成的文件。</p>
<p>Edits：记录客户端更新元数据信息的每一步操作（可通过Edits运算出元数据）。</p>
<p>​	NameNode启动时，先滚动Edits并生成一个空的edits.inprogress，然后加载Edits和Fsimage到内存中，此时NameNode内存就持有最新的元数据信息。Client开始对NameNode发送元数据的增删改的请求，这些请求的操作首先会被记录到edits.inprogress中（查询元数据的操作不会被记录在Edits中，因为查询操作不会更改元数据信息），如果此时NameNode挂掉，重启后会从Edits中读取元数据的信息。然后，NameNode会在内存中执行元数据的增删改的操作。</p>
<p>​	由于Edits中记录的操作会越来越多，Edits文件会越来越大，导致NameNode在启动加载Edits时会很慢，所以需要对Edits和Fsimage进行合并（所谓合并，就是将Edits和Fsimage加载到内存中，照着Edits中的操作一步步执行，最终形成新的Fsimage）。SecondaryNameNode的作用就是帮助NameNode进行Edits和Fsimage的合并工作。</p>
<p>​	SecondaryNameNode首先会询问NameNode是否需要CheckPoint（触发CheckPoint需要满足两个条件中的任意一个，定时时间到和Edits中数据写满了）。直接带回NameNode是否检查结果。SecondaryNameNode执行CheckPoint操作，首先会让NameNode滚动Edits并生成一个空的edits.inprogress，滚动Edits的目的是给Edits打个标记，以后所有新的操作都写入edits.inprogress，其他未合并的Edits和Fsimage会拷贝到SecondaryNameNode的本地，然后将拷贝的Edits和Fsimage加载到内存中进行合并，生成fsimage.chkpoint，然后将fsimage.chkpoint拷贝给NameNode，重命名为Fsimage后替换掉原来的Fsimage。NameNode在启动时就只需要加载之前未合并的Edits和Fsimage即可，因为合并过的Edits中的元数据信息已经被记录在Fsimage中。</p>
<h3 id="8-2CheckPoint时间设置"><a href="#8-2CheckPoint时间设置" class="headerlink" title="8.2CheckPoint时间设置"></a>8.2CheckPoint时间设置</h3><ol>
<li>通常情况下，SecondaryNameNode每隔一小时执行一次。</li>
<li>一分钟检查一次操作次数，当操作次数达到1百万时，SecondaryNameNode执行一次。</li>
</ol>
<h3 id="8-3集群的安全模式"><a href="#8-3集群的安全模式" class="headerlink" title="8.3集群的安全模式"></a>8.3集群的安全模式</h3><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661670551060.png" alt="1661670551060"></p>
<h2 id="9-DataNode"><a href="#9-DataNode" class="headerlink" title="9.DataNode"></a>9.DataNode</h2><h3 id="9-1DataNode工作机制"><a href="#9-1DataNode工作机制" class="headerlink" title="9.1DataNode工作机制"></a>9.1DataNode工作机制</h3><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661670644724.png" alt="1661670644724"></p>
<ol>
<li>一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳。</li>
<li>DataNode启动后向NameNode注册，通过后，周期性（1小时）的向NameNode上报所有的块信息。</li>
<li>心跳是每3秒一次，心跳返回结果带有NameNode给该DataNode的命令如复制块数据到另一台机器，或删除某个数据块。如果超过10分钟没有收到某个DataNode的心跳，则认为该节点不可用。</li>
<li>集群运行中可以安全加入和退出一些机器。</li>
</ol>
<h3 id="9-2DataNode检测数据完整性"><a href="#9-2DataNode检测数据完整性" class="headerlink" title="9.2DataNode检测数据完整性"></a>9.2DataNode检测数据完整性</h3><p>（1）当DataNode读取Block的时候，它会计算CheckSum。</p>
<p>（2）如果计算后的CheckSum，与Block创建时值不一样，说明Block已经损坏。</p>
<p>（3）Client读取其他DataNode上的Block。</p>
<p>（4）常见的校验算法 crc（32），md5（128），sha1（160）</p>
<p>（5）DataNode在其文件创建后周期验证CheckSum。</p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661671111412.png" alt="1661671111412"></p>
<h3 id="9-3DataNode掉线死亡时间的设置"><a href="#9-3DataNode掉线死亡时间的设置" class="headerlink" title="9.3DataNode掉线死亡时间的设置"></a>9.3DataNode掉线死亡时间的设置</h3><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661671219667.png" alt="1661671219667"></p>
<p>​	需要注意的是hdfs-site.xml 配置文件中的heartbeat.recheck.interval的单位为毫秒，dfs.heartbeat.interval的单位为秒。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;300000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.heartbeat.interval&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;3&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<h2 id="10-描述一下手写MR程序的大概流程和规范？"><a href="#10-描述一下手写MR程序的大概流程和规范？" class="headerlink" title="10.描述一下手写MR程序的大概流程和规范？"></a>10.描述一下手写MR程序的大概流程和规范？</h2><p>​	首先，从MapReduce程序的结构划分可以分为三部分，第一是 程序的执行入口通常简称为驱动类，驱动类主要编写MR作业的提交流程以及自定义的一些配置项。第二是 Map阶段的核心类需要自定并且继承Hadoop提供的Mapper类，重写Mapper类中的map方法，在map方法中遍写自己的业务逻辑代码将数据处理后利用context 上下文对象的写出落盘。第三是 Reduce阶段的核心类同时也需要继承Hadoop提供的Reducer类，并重写reduce 方法，在reduce方法中编写自己的业务逻辑代码，处理完数据后也是通过context上下文对象将数据写出，这也就是最终的结果文件。</p>
<h2 id="11-如何实现Hadoop中的序列化，以及和Java序列化的区别"><a href="#11-如何实现Hadoop中的序列化，以及和Java序列化的区别" class="headerlink" title="11.如何实现Hadoop中的序列化，以及和Java序列化的区别"></a>11.如何实现Hadoop中的序列化，以及和Java序列化的区别</h2><p>​	首先序列化是把内存中的Java对象转化成二进制字节码，反序列化是将二进制字节码转化成Java对象，通常我们在对Java对象进行磁盘持久化写入或者将Java对象作为数据进行网络传输的时候需要进行序列化，相反如果要将J数据从磁盘读出并转化成Java对象需要进行反序列化。实现Hadoop中的序列化需要让JavaBean对象实现Writable接口，并重写write() 方法和readFields()方法，其中write()方法是序列化方法，readFields()方法是反序列化方法。</p>
<p>​	Hadoop序列化和Java序列化的区别在于，Java序列化更重量级，Java序列化的后的结果不仅仅生成二进制字节码文件，同时还会针对当前Java对象生成对应的检验信息以及集成体系结构，这样的话 无形中我们需要维护更多的数据，但是Hadoop序列化不会产生除了Java对象内部属性外的任何信息，整体内容更加简洁紧凑，读写速度相应也会提升很多，这也符合了大数据的处理背景。</p>
<h2 id="12-描述一下MR程序的执行逻辑"><a href="#12-描述一下MR程序的执行逻辑" class="headerlink" title="12.描述一下MR程序的执行逻辑"></a>12.描述一下MR程序的执行逻辑</h2><p>​	简单的描述，MR程序执行先从InputFormat类说起，由InputFormat负责数据读入，并在内部实现切片，每一个切片的数据对应生成一个MapTask任务，MapTask中按照文件的行逐行数据进行处理，每一行数据会调用一次我们自定义的Mapper类的map方法，map方法内部实现具体的业务逻辑，处理完数据会通过context对象将数据写出到磁盘（此处会经历Shuffle过程），接下来ReduceTask会开始执行，首先ReduceTask会将MapTask处理完的数据结果拷贝过来，每一组相同key的values会会调用一次我们自定的Reducer类的reduce方法，当数据处理完成后，会通过context对象将数据结果写出到磁盘上。</p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661675103915.png" alt="1661675103915"></p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661675627909.png" alt="1661675627909"></p>
<p>上面的流程是整个MapReduce最全工作流程，但是Shuffle过程只是从第7步开始到第16步结束，具体Shuffle过程详解，如下：</p>
<p>（1）MapTask收集我们的map()方法输出的kv对，放到内存缓冲区中</p>
<p>（2）从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件</p>
<p>（3）多个溢出文件会被合并成大的溢出文件</p>
<p>（4）在溢出过程及合并的过程中，都要调用Partitioner进行分区和针对key进行排序</p>
<p>（5）ReduceTask根据自己的分区号，去各个MapTask机器上取相应的结果分区数据</p>
<p>（6）ReduceTask会抓取到同一个分区的来自不同MapTask的结果文件，ReduceTask会将这些文件再进行合并（归并排序）</p>
<p>（7）合并成大文件后，Shuffle的过程也就结束了，后面进入ReduceTask的逻辑运算过程（从文件中取出一个一个的键值对Group，调用用户自定义的reduce()方法）</p>
<p><strong>注意：</strong></p>
<p>（1）Shuffle中的缓冲区大小会影响到MapReduce程序的执行效率，原则上说，缓冲区越大，磁盘io的次数越少，执行速度就越快。</p>
<p>（2）缓冲区的大小可以通过参数调整，参数：mapreduce.task.io.sort.mb默认100M</p>
<h2 id="13-描述一下切片逻辑"><a href="#13-描述一下切片逻辑" class="headerlink" title="13.描述一下切片逻辑"></a>13.描述一下切片逻辑</h2><p>​	MR中的切片是发生在数据读入的阶段中，所以我们要关注InputFormat的实现，通过追溯源码，在InputFormat这个抽象类中有一个getSplits(),这个方法就是我们实现切片的具体逻辑。首先我们先关注两个变量，分别是 minSize 和 maxSize，通过对源码的跟踪默认情况 minSize &#x3D; 1，maxSize &#x3D; Long.MAX_VALUE，源码中声明了一个集合List<InputSplit> splits &#x3D; new ArrayList<InputSplit>();，用于装载将来的切片对象并返回。接下来我们根据提交的job信息获取到当前要进行切片的文件详情，首先判断点前文件是否可以进行切分，这一步主要考虑到一些不支持切分的压缩文件时不能进行切片操作，否则就破坏了数据的完整性，如果当前文件可以切片的话，那么接下来就要计算切片的大小，计算切片大小一共需要三个因子，分别是minSize 、maxSize 、blocksize ，最后通过Math.max(minSize, Math.min(maxSize, blockSize)); 计算逻辑获取到切片大小，默认情况切片大小和数据库块大小一致，如果我们想改变切片大小可以通过修改一下两个配置参数实现 mapreduce.input.fileinputformat.split.minsize mapreduce.input.fileinputformat.split.maxsize，</p>
<p>如果把切片大小调大改mapreduce.input.fileinputformat.split.minsize<br>如果把切片大小调小改mapreduce.input.fileinputformat.split.maxsize。</p>
<p>​	当我们可以获取到切片大小后就可以继续往下执行，在最终完成切片之前还有一个关键判断，就是判断剩余文件是否要继续进行切片，如果剩余文件&#x2F;切片大小&gt;1.1 那就继续切片，否则就不会再进行切片，这个规则考虑的情况就就是让将来的切片尽可能资源使用均衡，不至于很小的文件内容也开启一个MapTask。到此整个切片规则就表述完毕了！</p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661674494603.png" alt="1661674494603"></p>
<h2 id="14-CombineTextInputFormat切片机制"><a href="#14-CombineTextInputFormat切片机制" class="headerlink" title="14.CombineTextInputFormat切片机制"></a>14.CombineTextInputFormat切片机制</h2><p>​	框架默认的TextInputFormat切片机制是对任务按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个MapTask，这样如果有大量小文件，就会产生大量的MapTask，处理效率极其低下。</p>
<p>​	CombineTextInputFormat用于小文件过多的场景，它可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个MapTask处理。</p>
<p>​	CombineTextInputFormat.setMaxInputSplitSize(job, 4194304);&#x2F;&#x2F; 4m</p>
<p>​	注意：虚拟存储切片最大值设置最好根据实际的小文件大小情况来设置具体的值。</p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661674832817.png" alt="1661674832817"></p>
<p>​	将输入目录下所有文件大小，依次和设置的setMaxInputSplitSize值比较，如果不大于设置的最大值，逻辑上划分一个块。如果输入文件大于设置的最大值且大于两倍，那么以最大值切割一块；当剩余数据大小超过设置的最大值且不大于最大值2倍，此时将文件均分成2个虚拟存储块（防止出现太小切片）。</p>
<p>​	例如setMaxInputSplitSize值为4M，输入文件大小为8.02M，则先逻辑上分成一个4M。剩余的大小为4.02M，如果按照4M逻辑划分，就会出现0.02M的小的虚拟存储文件，所以将剩余的4.02M文件切分成（2.01M和2.01M）两个文件。</p>
<h2 id="15-MR中的shuffle机制"><a href="#15-MR中的shuffle机制" class="headerlink" title="15.MR中的shuffle机制"></a>15.MR中的shuffle机制</h2><h3 id="15-1概述"><a href="#15-1概述" class="headerlink" title="15.1概述"></a>15.1概述</h3><p>​	Map方法之后，Reduce方法之前的数据处理过程称之为Shuffle。</p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661675886296.png" alt="1661675886296"></p>
<h3 id="15-2Partion分区"><a href="#15-2Partion分区" class="headerlink" title="15.2Partion分区"></a>15.2Partion分区</h3><p>默认的分区是根据key的hashcode对于ReduceTask的数量取余得到的，用户没办法指定key在哪一个分区</p>
<p><strong>自定义Partition步骤：</strong></p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661676742763.png" alt="1661676742763"></p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661676800867.png" alt="1661676800867"></p>
<h3 id="15-3WritableComparable排序"><a href="#15-3WritableComparable排序" class="headerlink" title="15.3WritableComparable排序"></a>15.3WritableComparable排序</h3><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661676891089.png" alt="1661676891089"></p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661676953729.png" alt="1661676953729"></p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661676989320.png" alt="1661676989320"></p>
<p><strong>自定义排序WritableComparable原理分析</strong></p>
<p>bean对象做为key传输，需要实现WritableComparable接口重写compareTo方法，就可以实现排序。</p>
<h3 id="15-3Combiner"><a href="#15-3Combiner" class="headerlink" title="15.3Combiner"></a>15.3Combiner</h3><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661677337910.png" alt="1661677337910"></p>
<h2 id="16-MapTask的工作机制"><a href="#16-MapTask的工作机制" class="headerlink" title="16.MapTask的工作机制"></a>16.MapTask的工作机制</h2><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661677599289.png" alt="1661677599289"></p>
<p>​	（1）Read阶段：MapTask通过InputFormat获得的RecordReader，从输入InputSplit中解析出一个个key&#x2F;value。</p>
<p>​       （2）Map阶段：该节点主要是将解析出的key&#x2F;value交给用户编写map()函数处理，并产生一系列新的key&#x2F;value。</p>
<p>​       （3）Collect收集阶段：在用户编写map()函数中，当数据处理完成后，一般会调用OutputCollector.collect()输出结果。在该函数内部，它会将生成的key&#x2F;value分区（调用Partitioner），并写入一个环形内存缓冲区中。</p>
<p>​       （4）Spill阶段：即“溢写”，当环形缓冲区满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。</p>
<p>​       溢写阶段详情：</p>
<p>​       步骤1：利用快速排序算法对缓存区内的数据进行排序，排序方式是，先按照分区编号Partition进行排序，然后按照key进行排序。这样，经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照key有序。</p>
<p>​       步骤2：按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件output&#x2F;spillN.out（N表示当前溢写次数）中。如果用户设置了Combiner，则写入文件之前，对每个分区中的数据进行一次聚集操作。</p>
<p>​       步骤3：将分区数据的元信息写到内存索引数据结构SpillRecord中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过1MB，则将内存索引写到文件output&#x2F;spillN.out.index中。</p>
<p>​       （5）Merge阶段：当所有数据处理完成后，MapTask对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。</p>
<p>​       当所有数据处理完后，MapTask会将所有临时文件合并成一个大文件，并保存到文件output&#x2F;file.out中，同时生成相应的索引文件output&#x2F;file.out.index。</p>
<p>​       在进行文件合并过程中，MapTask以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的方式。每轮合并mapreduce.task.io.sort.factor（默认10）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件。</p>
<p>​       让每个MapTask最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销。</p>
<h2 id="17-ReduceTask的工作机制"><a href="#17-ReduceTask的工作机制" class="headerlink" title="17.ReduceTask的工作机制"></a>17.ReduceTask的工作机制</h2><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661677648908.png" alt="1661677648908"></p>
<p>​       （1）Copy阶段：ReduceTask从各个MapTask上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</p>
<p>​       （2）Merge阶段：在远程拷贝数据的同时，ReduceTask启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。</p>
<p>​       （3）Sort阶段：按照MapReduce语义，用户编写reduce()函数输入数据是按key进行聚集的一组数据。为了将key相同的数据聚在一起，Hadoop采用了基于排序的策略。由于各个MapTask已经实现对自己的处理结果进行了局部排序，因此，ReduceTask只需对所有数据进行一次归并排序即可。</p>
<p>​       （4）Reduce阶段：reduce()函数将计算结果写到HDFS上。</p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661677707796.png" alt="1661677707796"></p>
<h2 id="18-Map-Join-和Reduce-Join"><a href="#18-Map-Join-和Reduce-Join" class="headerlink" title="18.Map Join 和Reduce Join"></a>18.Map Join 和Reduce Join</h2><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661678941793.png" alt="1661678941793"></p>
<p>​	Map Join适用于一张表十分小、一张表很大的场景。</p>
<h2 id="19-Yarn的工作机制"><a href="#19-Yarn的工作机制" class="headerlink" title="19.Yarn的工作机制"></a>19.Yarn的工作机制</h2><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661679074675.png" alt="1661679074675"></p>
<p>​	（1）MR程序提交到客户端所在的节点。</p>
<p>​       （2）YarnRunner向ResourceManager申请一个Application。</p>
<p>​       （3）RM将该应用程序的资源路径返回给YarnRunner。</p>
<p>​       （4）该程序将运行所需资源提交到HDFS上。</p>
<p>​       （5）程序资源提交完毕后，申请运行mrAppMaster。</p>
<p>​       （6）RM将用户的请求初始化成一个Task。</p>
<p>​       （7）其中一个NodeManager领取到Task任务。</p>
<p>​       （8）该NodeManager创建容器Container，并产生MRAppmaster。</p>
<p>​       （9）Container从HDFS上拷贝资源到本地。</p>
<p>​       （10）MRAppmaster向RM 申请运行MapTask资源。</p>
<p>​       （11）RM将运行MapTask任务分配给另外两个NodeManager，另两个NodeManager分别领取任务并创建容器。</p>
<p>​       （12）MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动MapTask，MapTask对数据分区排序。</p>
<p>​	（13）MrAppMaster等待所有MapTask运行完毕后，向RM申请容器，运行ReduceTask。</p>
<p>​       （14）ReduceTask向MapTask获取相应分区的数据。</p>
<p>​       （15）程序运行完毕后，MR会向RM申请注销自己。</p>
<hr>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661679214814.png" alt="1661679214814"></p>
<p>作业提交全过程详解</p>
<p>（1）作业提交</p>
<p>第1步：Client调用job.waitForCompletion方法，向整个集群提交MapReduce作业。</p>
<p>第2步：Client向RM申请一个作业id。</p>
<p>第3步：RM给Client返回该job资源的提交路径和作业id。</p>
<p>第4步：Client提交jar包、切片信息和配置文件到指定的资源提交路径。</p>
<p>第5步：Client提交完资源后，向RM申请运行MrAppMaster。</p>
<p>（2）作业初始化</p>
<p>第6步：当RM收到Client的请求后，将该job添加到容量调度器中。</p>
<p>第7步：某一个空闲的NM领取到该Job。</p>
<p>第8步：该NM创建Container，并产生MRAppmaster。</p>
<p>第9步：下载Client提交的资源到本地。</p>
<p>（3）任务分配</p>
<p>第10步：MrAppMaster向RM申请运行多个MapTask任务资源。</p>
<p>第11步：RM将运行MapTask任务分配给另外两个NodeManager，另两个NodeManager分别领取任务并创建容器。</p>
<p>（4）任务运行</p>
<p>第12步：MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动MapTask，MapTask对数据分区排序。</p>
<p>第13步：MrAppMaster等待所有MapTask运行完毕后，向RM申请容器，运行ReduceTask。</p>
<p>第14步：ReduceTask向MapTask获取相应分区的数据。</p>
<p>第15步：程序运行完毕后，MR会向RM申请注销自己。</p>
<p>（5）进度和状态更新</p>
<p>YARN中的任务将其进度和状态(包括counter)返回给应用管理器, 客户端每秒(通过mapreduce.client.progressmonitor.pollinterval设置)向应用管理器请求进度更新, 展示给用户。</p>
<p>（6）作业完成</p>
<p>除了向应用管理器请求作业进度外, 客户端每5秒都会通过调用waitForCompletion()来检查作业是否完成。时间间隔可以通过mapreduce.client.completion.pollinterval来设置。作业完成之后, 应用管理器和Container会清理工作状态。作业的信息会被作业历史服务器存储以备之后用户核查。</p>
<h2 id="20-Hadoop中的作业调度器"><a href="#20-Hadoop中的作业调度器" class="headerlink" title="20.Hadoop中的作业调度器"></a>20.Hadoop中的作业调度器</h2><p>​	目前，Hadoop作业调度器主要有三种：FIFO、Capacity Scheduler和Fair Scheduler。Hadoop3.1.3默认的资源调度器是Capacity Scheduler。</p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661679354061.png" alt="1661679354061"></p>
<p>​	Hadoop最初设计目的是支持大数据批处理作业，如日志挖掘、Web索引等作业，</p>
<p>​	为此，Hadoop仅提供了一个非常简单的调度机制：FIFO，即先来先服务，在该调度机制下，所有作业被统一提交到一个队列中，Hadoop按照提交顺序依次运行这些作业。</p>
<p>​	但随着Hadoop的普及，单个Hadoop集群的用户量越来越大，不同用户提交的应用程序往往具有不同的服务质量要求，典型的应用有以下几种：</p>
<p>​	批处理作业：这种作业往往耗时较长，对时间完成一般没有严格要求，如数据挖掘、机器学习等方面的应用程序。</p>
<p>​	交互式作业：这种作业期望能及时返回结果，如SQL查询（Hive）等。</p>
<p>​	生产性作业：这种作业要求有一定量的资源保证，如统计值计算、垃圾数据分析等。</p>
<p>​	此外，这些应用程序对硬件资源需求量也是不同的，如过滤、统计类作业一般为CPU密集型作业，而数据挖掘、机器学习作业一般为I&#x2F;O密集型作业。因此，简单的FIFO调度策略不仅不能满足多样化需求，也不能充分利用硬件资源。</p>
<hr>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661679393543.png" alt="1661679393543"></p>
<p>​	Capacity Scheduler Capacity Scheduler 是Yahoo开发的多用户调度器，它以队列为单位划分资源，每个队列可设定一定比例的资源最低保证和使用上限，同时，每个用户也可设定一定的资源使用上限以防止资源滥用。而当一个队列的资源有剩余时，可暂时将剩余资源共享给其他队列。</p>
<p>​	总之，Capacity Scheduler 主要有以下几个特点：</p>
<p>​	①容量保证。管理员可为每个队列设置资源最低保证和资源使用上限，而所有提交到该队列的应用程序共享这些资源。</p>
<p>​	②灵活性，如果一个队列中的资源有剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用程序提交，则其他队列借调的资源会归还给该队列。这种资源灵活分配的方式可明显提高资源利用率。</p>
<p>​	③多重租赁。支持多用户共享集群和多应用程序同时运行。为防止单个应用程序、用户或者队列独占集群中的资源，管理员可为之增加多重约束（比如单个应用程序同时运行的任务数等）。</p>
<p>​	④安全保证。每个队列有严格的ACL列表规定它的访问用户，每个用户可指定哪些用户允许查看自己应用程序的运行状态或者控制应用程序（比如杀死应用程序）。此外，管理员可指定队列管理员和集群系统管理员。</p>
<p>​	⑤动态更新配置文件。管理员可根据需要动态修改各种配置参数，以实现在线集群管理。</p>
<h2 id="21-Hadoop的数据压缩"><a href="#21-Hadoop的数据压缩" class="headerlink" title="21.Hadoop的数据压缩"></a>21.Hadoop的数据压缩</h2><h3 id="21-1概述"><a href="#21-1概述" class="headerlink" title="21.1概述"></a>21.1概述</h3><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661686071085.png" alt="1661686071085"></p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661686077793.png" alt="1661686077793"></p>
<h3 id="21-2MR支持的压缩编码"><a href="#21-2MR支持的压缩编码" class="headerlink" title="21.2MR支持的压缩编码"></a>21.2MR支持的压缩编码</h3><table>
<thead>
<tr>
<th>压缩格式</th>
<th>hadoop自带？</th>
<th>算法</th>
<th>文件扩展名</th>
<th>是否可切分</th>
<th>换成压缩格式后，原来的程序是否需要修改</th>
</tr>
</thead>
<tbody><tr>
<td>DEFLATE</td>
<td>是，直接使用</td>
<td>DEFLATE</td>
<td>.deflate</td>
<td>否</td>
<td>和文本处理一样，不需要修改</td>
</tr>
<tr>
<td>Gzip</td>
<td>是，直接使用</td>
<td>DEFLATE</td>
<td>.gz</td>
<td>否</td>
<td>和文本处理一样，不需要修改</td>
</tr>
<tr>
<td>bzip2</td>
<td>是，直接使用</td>
<td>bzip2</td>
<td>.bz2</td>
<td>是</td>
<td>和文本处理一样，不需要修改</td>
</tr>
<tr>
<td>LZO</td>
<td>否，需要安装</td>
<td>LZO</td>
<td>.lzo</td>
<td>是</td>
<td>需要建索引，还需要指定输入格式</td>
</tr>
<tr>
<td>Snappy</td>
<td>是，直接使用</td>
<td>Snappy</td>
<td>.snappy</td>
<td>否</td>
<td>和文本处理一样，不需要修改</td>
</tr>
</tbody></table>
<p>为了支持多种压缩&#x2F;解压缩算法，Hadoop引入了编码&#x2F;解码器，如下表所示。</p>
<table>
<thead>
<tr>
<th>压缩格式</th>
<th>对应的编码&#x2F;解码器</th>
</tr>
</thead>
<tbody><tr>
<td>DEFLATE</td>
<td>org.apache.hadoop.io.compress.DefaultCodec</td>
</tr>
<tr>
<td>gzip</td>
<td>org.apache.hadoop.io.compress.GzipCodec</td>
</tr>
<tr>
<td>bzip2</td>
<td>org.apache.hadoop.io.compress.BZip2Codec</td>
</tr>
<tr>
<td>LZO</td>
<td>com.hadoop.compression.lzo.LzopCodec</td>
</tr>
<tr>
<td>Snappy</td>
<td>org.apache.hadoop.io.compress.SnappyCodec</td>
</tr>
</tbody></table>
<p>压缩性能的比较</p>
<table>
<thead>
<tr>
<th>压缩算法</th>
<th>原始文件大小</th>
<th>压缩文件大小</th>
<th>压缩速度</th>
<th>解压速度</th>
</tr>
</thead>
<tbody><tr>
<td>gzip</td>
<td>8.3GB</td>
<td>1.8GB</td>
<td>17.5MB&#x2F;s</td>
<td>58MB&#x2F;s</td>
</tr>
<tr>
<td>bzip2</td>
<td>8.3GB</td>
<td>1.1GB</td>
<td>2.4MB&#x2F;s</td>
<td>9.5MB&#x2F;s</td>
</tr>
<tr>
<td>LZO</td>
<td>8.3GB</td>
<td>2.9GB</td>
<td>49.3MB&#x2F;s</td>
<td>74.6MB&#x2F;s</td>
</tr>
</tbody></table>
<h3 id="21-3压缩方式的选择"><a href="#21-3压缩方式的选择" class="headerlink" title="21.3压缩方式的选择"></a>21.3压缩方式的选择</h3><h4 id="21-3-1Gzip压缩"><a href="#21-3-1Gzip压缩" class="headerlink" title="21.3.1Gzip压缩"></a>21.3.1Gzip压缩</h4><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661686251985.png" alt="1661686251985"></p>
<h4 id="21-3-2Bzip2压缩"><a href="#21-3-2Bzip2压缩" class="headerlink" title="21.3.2Bzip2压缩"></a>21.3.2Bzip2压缩</h4><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661686270207.png" alt="1661686270207"></p>
<h4 id="21-3-3Lzo压缩"><a href="#21-3-3Lzo压缩" class="headerlink" title="21.3.3Lzo压缩"></a>21.3.3Lzo压缩</h4><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661686290319.png" alt="1661686290319"></p>
<h4 id="21-3-4-Snappy压缩"><a href="#21-3-4-Snappy压缩" class="headerlink" title="21.3.4 Snappy压缩"></a>21.3.4 Snappy压缩</h4><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661686312779.png" alt="1661686312779"></p>
<h3 id="21-4压缩位置选择"><a href="#21-4压缩位置选择" class="headerlink" title="21.4压缩位置选择"></a>21.4压缩位置选择</h3><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661686358694.png" alt="1661686358694"></p>
<h3 id="21-5压缩参数配置"><a href="#21-5压缩参数配置" class="headerlink" title="21.5压缩参数配置"></a>21.5压缩参数配置</h3><p>​	要在Hadoop中启用压缩，可以配置如下参数：</p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661686428791.png" alt="1661686428791"></p>
<h2 id="22-Hadoop企业优化"><a href="#22-Hadoop企业优化" class="headerlink" title="22.Hadoop企业优化"></a>22.Hadoop企业优化</h2><h3 id="22-1MapReduce跑的慢的原因"><a href="#22-1MapReduce跑的慢的原因" class="headerlink" title="22.1MapReduce跑的慢的原因"></a>22.1MapReduce跑的慢的原因</h3><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661686500161.png" alt="1661686500161"></p>
<h3 id="22-2MapReduce优化方法"><a href="#22-2MapReduce优化方法" class="headerlink" title="22.2MapReduce优化方法"></a>22.2MapReduce优化方法</h3><p>​	MapReduce优化方法主要从六个方面考虑：数据输入、Map阶段、Reduce阶段、IO传输、数据倾斜问题和常用的调优参数。</p>
<h4 id="22-2-1数据输入"><a href="#22-2-1数据输入" class="headerlink" title="22.2.1数据输入"></a>22.2.1数据输入</h4><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661686594807.png" alt="1661686594807"></p>
<h4 id="22-2-2Map阶段"><a href="#22-2-2Map阶段" class="headerlink" title="22.2.2Map阶段"></a>22.2.2Map阶段</h4><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661686606515.png" alt="1661686606515"></p>
<h4 id="22-2-3-Reduce阶段"><a href="#22-2-3-Reduce阶段" class="headerlink" title="22.2.3 Reduce阶段"></a>22.2.3 Reduce阶段</h4><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661686621134.png" alt="1661686621134"></p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661686630210.png" alt="1661686630210"></p>
<h4 id="22-2-4IO阶段"><a href="#22-2-4IO阶段" class="headerlink" title="22.2.4IO阶段"></a>22.2.4IO阶段</h4><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661686637490.png" alt="1661686637490"></p>
<h4 id="22-2-5数据倾斜问题"><a href="#22-2-5数据倾斜问题" class="headerlink" title="22.2.5数据倾斜问题"></a>22.2.5数据倾斜问题</h4><p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661686653447.png" alt="1661686653447"></p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661686661689.png" alt="1661686661689"></p>
<h3 id="22-3常用的调优参数"><a href="#22-3常用的调优参数" class="headerlink" title="22.3常用的调优参数"></a>22.3常用的调优参数</h3><p>（1）以下参数是在用户自己的MR应用程序中配置就可以生效（mapred-default.xml）</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数说明</th>
</tr>
</thead>
<tbody><tr>
<td>mapreduce.map.memory.mb</td>
<td>一个MapTask可使用的资源上限（单位:MB），默认为1024。如果MapTask实际使用的资源量超过该值，则会被强制杀死。</td>
</tr>
<tr>
<td>mapreduce.reduce.memory.mb</td>
<td>一个ReduceTask可使用的资源上限（单位:MB），默认为1024。如果ReduceTask实际使用的资源量超过该值，则会被强制杀死。</td>
</tr>
<tr>
<td>mapreduce.map.cpu.vcores</td>
<td>每个MapTask可使用的最多cpu core数目，默认值: 1</td>
</tr>
<tr>
<td>mapreduce.reduce.cpu.vcores</td>
<td>每个ReduceTask可使用的最多cpu   core数目，默认值: 1</td>
</tr>
<tr>
<td>mapreduce.reduce.shuffle.parallelcopies</td>
<td>每个Reduce去Map中取数据的并行数。默认值是5</td>
</tr>
<tr>
<td>mapreduce.reduce.shuffle.merge.percent</td>
<td>Buffer中的数据达到多少比例开始写入磁盘。默认值0.66</td>
</tr>
<tr>
<td>mapreduce.reduce.shuffle.input.buffer.percent</td>
<td>Buffer大小占Reduce可用内存的比例。默认值0.7</td>
</tr>
<tr>
<td>mapreduce.reduce.input.buffer.percent</td>
<td>指定多少比例的内存用来存放Buffer中的数据，默认值是0.0</td>
</tr>
</tbody></table>
<p>（2）应该在YARN启动之前就配置在服务器的配置文件中才能生效（yarn-default.xml）</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数说明</th>
</tr>
</thead>
<tbody><tr>
<td>yarn.scheduler.minimum-allocation-mb</td>
<td>给应用程序Container分配的最小内存，默认值：1024</td>
</tr>
<tr>
<td>yarn.scheduler.maximum-allocation-mb</td>
<td>给应用程序Container分配的最大内存，默认值：8192</td>
</tr>
<tr>
<td>yarn.scheduler.minimum-allocation-vcores</td>
<td>每个Container申请的最小CPU核数，默认值：1</td>
</tr>
<tr>
<td>yarn.scheduler.maximum-allocation-vcores</td>
<td>每个Container申请的最大CPU核数，默认值：32</td>
</tr>
<tr>
<td>yarn.nodemanager.resource.memory-mb</td>
<td>给Containers分配的最大物理内存，默认值：8192</td>
</tr>
</tbody></table>
<p>（3）Shuffle性能优化的关键参数，应在YARN启动之前就配置好（mapred-default.xml）</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数说明</th>
</tr>
</thead>
<tbody><tr>
<td>mapreduce.task.io.sort.mb</td>
<td>Shuffle的环形缓冲区大小，默认100m</td>
</tr>
<tr>
<td>mapreduce.map.sort.spill.percent</td>
<td>环形缓冲区溢出的阈值，默认80%</td>
</tr>
</tbody></table>
<p>容错相关配置</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数说明</th>
</tr>
</thead>
<tbody><tr>
<td>mapreduce.map.maxattempts</td>
<td>每个Map Task最大重试次数，一旦重试次数超过该值，则认为Map Task运行失败，默认值：4。</td>
</tr>
<tr>
<td>mapreduce.reduce.maxattempts</td>
<td>每个Reduce Task最大重试次数，一旦重试次数超过该值，则认为Map Task运行失败，默认值：4。</td>
</tr>
<tr>
<td>mapreduce.task.timeout</td>
<td>Task超时时间，经常需要设置的一个参数，该参数表达的意思为：如果一个Task在一定时间内没有任何进入，即不会读取新的数据，也没有输出数据，则认为该Task处于Block状态，可能是卡住了，也许永远会卡住，为了防止因为用户程序永远Block住不退出，则强制设置了一个该超时时间（单位毫秒），默认是600000（10分钟）。如果你的程序对每条输入数据的处理时间过长（比如会访问数据库，通过网络拉取数据等），建议将该参数调大，该参数过小常出现的错误提示是：“AttemptID:attempt_14267829456721_123456_m_000224_0 Timed out after   300 secsContainer killed by the ApplicationMaster.”。</td>
</tr>
</tbody></table>
<h3 id="22-4Hadoop小文件优化方法"><a href="#22-4Hadoop小文件优化方法" class="headerlink" title="22.4Hadoop小文件优化方法"></a>22.4Hadoop小文件优化方法</h3><h4 id="22-4-1Hadoop小文件弊端"><a href="#22-4-1Hadoop小文件弊端" class="headerlink" title="22.4.1Hadoop小文件弊端"></a>22.4.1Hadoop小文件弊端</h4><p>​	HDFS上每个文件都要在NameNode上创建对应的元数据，这个元数据的大小约为150byte，这样当小文件比较多的时候，就会产生很多的元数据文件，一方面会大量占用NameNode的内存空间，另一方面就是元数据文件过多，使得寻址索引速度变慢。</p>
<p>​	小文件过多，在进行MR计算时，会生成过多切片，需要启动过多的MapTask。每个MapTask处理的数据量小，导致MapTask的处理时间比启动时间还小，白白消耗资源。</p>
<h4 id="22-4-2Hadoop小文件解决方法"><a href="#22-4-2Hadoop小文件解决方法" class="headerlink" title="22.4.2Hadoop小文件解决方法"></a>22.4.2Hadoop小文件解决方法</h4><ol>
<li><pre><code>  小文件优化的方向：
</code></pre>
</li>
</ol>
<p>（1）在数据采集的时候，就将小文件或小批数据合成大文件再上传HDFS。</p>
<p>（2）在业务处理之前，在HDFS上使用MapReduce程序对小文件进行合并。</p>
<p>（3）在MapReduce处理时，可采用CombineTextInputFormat提高效率。</p>
<p>（4）开启uber模式，实现jvm重用</p>
<ol start="2">
<li><pre><code>  Hadoop Archive
</code></pre>
</li>
</ol>
<p>是一个高效的将小文件放入HDFS块中的文件存档工具，能够将多个小文件打包成一个HAR文件，从而达到减少NameNode的内存使用</p>
<ol start="3">
<li><pre><code>  SequenceFile
</code></pre>
</li>
</ol>
<p>SequenceFile是由一系列的二进制k&#x2F;v组成，如果为key为文件名，value为文件内容，可将大批小文件合并成一个大文件</p>
<ol start="4">
<li><pre><code>  CombineTextInputFormat
</code></pre>
</li>
</ol>
<p>CombineTextInputFormat用于将多个小文件在切片过程中生成一个单独的切片或者少量的切片。 </p>
<ol start="5">
<li><pre><code>  开启uber模式，实现jvm重用。默认情况下，每个Task任务都需要启动一个jvm来运行，如果Task任务计算的数据量很小，我们可以让同一个Job的多个Task运行在一个Jvm中，不必为每个Task都开启一个Jvm.
</code></pre>
</li>
</ol>
<p>开启uber模式，在mapred-site.xml中添加如下配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--  开启uber模式 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.job.ubertask.enable&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- uber模式中最大的mapTask数量，可向下修改  --&gt; </span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.job.ubertask.maxmaps&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;9&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- uber模式中最大的reduce数量，可向下修改 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.job.ubertask.maxreduces&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- uber模式中最大的输入数据量，默认使用dfs.blocksize 的值，可向下修改 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.job.ubertask.maxbytes&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<h2 id="23-Hadoop3-x的新特性"><a href="#23-Hadoop3-x的新特性" class="headerlink" title="23.Hadoop3.x的新特性"></a>23.Hadoop3.x的新特性</h2><h3 id="23-1多NN的HA架构"><a href="#23-1多NN的HA架构" class="headerlink" title="23.1多NN的HA架构"></a>23.1多NN的HA架构</h3><p>​	 HDFS NameNode高可用性的初始实现为单个活动NameNode和单个备用NameNode，将edits复制到三个JournalNode。该体系结构能够容忍系统中一个NN或一个JN的故障。</p>
<p>​	但是，某些部署需要更高程度的容错能力。Hadoop3.x允许用户运行多个备用NameNode。例如，通过配置三个NameNode和五个JournalNode，群集能够容忍两个节点而不是一个节点的故障。</p>
<h3 id="23-2纠删码"><a href="#23-2纠删码" class="headerlink" title="23.2纠删码"></a>23.2纠删码</h3><pre><code> HDFS中的默认3副本方案在存储空间和其他资源（例如，网络带宽）中具有200％的开销。但是，对于I / O活动相对较低暖和冷数据集，在正常操作期间很少访问其他块副本，但仍会消耗与第一个副本相同的资源量。
</code></pre>
<p>​	 纠删码（Erasure Coding）能够在不到50% 的数据冗余情况下提供和3副本相同的容错能力，因此，使用纠删码作为副本机制的改进是自然而然的。</p>
<p>​	查看集群支持的纠删码策略：hdfs ec -listPolicies</p>
<h2 id="24-Hadoop-HA高可用"><a href="#24-Hadoop-HA高可用" class="headerlink" title="24.Hadoop HA高可用"></a>24.Hadoop HA高可用</h2><h3 id="24-1概述"><a href="#24-1概述" class="headerlink" title="24.1概述"></a>24.1概述</h3><p>（1）所谓HA（High Availablity），即高可用（7*24小时不中断服务）。</p>
<p>（2）实现高可用最关键的策略是消除单点故障。HA严格来说应该分成各个组件的HA机制：HDFS的HA和YARN的HA。</p>
<p>（3）Hadoop2.0之前，在HDFS集群中NameNode存在单点故障（SPOF）。</p>
<p>（4）NameNode主要在以下两个方面影响HDFS集群</p>
<p>​	Ø  NameNode机器发生意外，如宕机，集群将无法使用，直到管理员重启</p>
<p>​	Ø  NameNode机器需要升级，包括软件、硬件升级，此时集群也将无法使用</p>
<p>​	</p>
<p>​	HDFS HA功能通过配置Active&#x2F;Standby两个NameNodes实现在集群中对NameNode的热备来解决上述问题。如果出现故障，如机器崩溃或机器需要升级维护，这时可通过此种方式将NameNode很快的切换到另外一台机器。</p>
<h3 id="24-2工作原理"><a href="#24-2工作原理" class="headerlink" title="24.2工作原理"></a>24.2工作原理</h3><p>1）元数据管理方式需要改变</p>
<p>​	内存中各自保存一份元数据；</p>
<p>​	Edits日志只有Active状态的NameNode节点可以做写操作；</p>
<p>​	所有的NameNode都可以读取Edits；</p>
<p>​	共享的Edits放在一个共享存储中管理（qjournal和NFS两个主流实现）；</p>
<p>2）需要一个状态管理功能模块</p>
<p>​	实现了一个zkfailover，常驻在每一个namenode所在的节点，每一个zkfailover负责监控自己所在NameNode节点，利用zk进行状态标识，当需要进行状态切换时，由zkfailover来负责切换，切换时需要防止brain split现象的发生。</p>
<p>3）必须保证两个NameNode之间能够ssh无密码登录</p>
<p>4）隔离（Fence），即同一时刻仅仅有一个NameNode对外提供服务</p>
<h3 id="24-3HDFS-HA自动故障转移工作机制"><a href="#24-3HDFS-HA自动故障转移工作机制" class="headerlink" title="24.3HDFS-HA自动故障转移工作机制"></a>24.3HDFS-HA自动故障转移工作机制</h3><p>自动故障转移为HDFS部署增加了两个新组件：ZooKeeper和ZKFailoverController（ZKFC）进程，如图3-20所示。ZooKeeper是维护少量协调数据，通知客户端这些数据的改变和监视客户端故障的高可用服务。HA的自动故障转移依赖于ZooKeeper的以下功能：</p>
<p><strong>1．故障检测</strong></p>
<p>集群中的每个NameNode在ZooKeeper中维护了一个会话，如果机器崩溃，ZooKeeper中的会话将终止，ZooKeeper通知另一个NameNode需要触发故障转移。</p>
<p><strong>2．现役NameNode选择</strong></p>
<p>ZooKeeper提供了一个简单的机制用于唯一的选择一个节点为active状态。如果目前现役NameNode崩溃，另一个节点可能从ZooKeeper获得特殊的排外锁以表明它应该成为现役NameNode。</p>
<p>ZKFC是自动故障转移中的另一个新组件，是ZooKeeper的客户端，也监视和管理NameNode的状态。每个运行NameNode的主机也运行了一个ZKFC进程，ZKFC负责：</p>
<p><strong>1）健康监测</strong></p>
<p>ZKFC使用一个健康检查命令定期地ping与之在相同主机的NameNode，只要该NameNode及时地回复健康状态，ZKFC认为该节点是健康的。如果该节点崩溃，冻结或进入不健康状态，健康监测器标识该节点为非健康的。</p>
<p><strong>2）ZooKeeper会话管理</strong></p>
<p>当本地NameNode是健康的，ZKFC保持一个在ZooKeeper中打开的会话。如果本地NameNode处于active状态，ZKFC也保持一个特殊的znode锁，该锁使用了ZooKeeper对短暂节点的支持，如果会话终止，锁节点将自动删除。</p>
<p><strong>3）基于ZooKeeper的选择</strong></p>
<p>如果本地NameNode是健康的，且ZKFC发现没有其它的节点当前持有znode锁，它将为自己获取该锁。如果成功，则它已经赢得了选择，并负责运行故障转移进程以使它的本地NameNode为Active。</p>
<p><img src="/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/1661687659347.png" alt="1661687659347"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Xiang Liu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/">http://example.com/2022/08/28/Hadoop/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">The Xiang Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/MR/">MR</a><a class="post-meta__tags" href="/tags/HDFS/">HDFS</a><a class="post-meta__tags" href="/tags/Yarn/">Yarn</a></div><div class="post_share"><div class="social-share" data-image="/../image/bg.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/08/28/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E9%A1%B9%E7%9B%AE/%E5%87%86%E5%A4%87%E6%A8%A1%E6%9D%BF%E6%9C%BA/"><img class="prev-cover" src="/../image/bg.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">准备一台模板机</div></div></a></div><div class="next-post pull-right"><a href="/2022/08/27/shell/shell/"><img class="next-cover" src="/../image/bg.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">shell的一些基本用法</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/./image/title.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Xiang Liu</div><div class="author-info__description">欢迎访问我的博客</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">88</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/theXiangCode" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://mail.qq.com/" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">这几天心理颇不宁静</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Hadoop%E7%9A%84%E4%BC%98%E5%8A%BF%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-text">1.Hadoop的优势是什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Hadoop1%E7%89%88%E6%9C%AC%E5%92%8CHadoop2%E7%89%88%E6%9C%AC%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-text">2.Hadoop1版本和Hadoop2版本的区别？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-HDFS%E6%9E%B6%E6%9E%84%E7%AE%80%E8%BF%B0%EF%BC%9F"><span class="toc-text">3.HDFS架构简述？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Yarn%E6%9E%B6%E6%9E%84%E7%AE%80%E8%BF%B0%EF%BC%9F"><span class="toc-text">4.Yarn架构简述？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E4%B8%BA%E4%BB%80%E4%B9%88HDFS%E6%96%87%E4%BB%B6%E5%9D%97%E8%AE%BE%E7%BD%AE%E4%B8%BA128MB%EF%BC%9F"><span class="toc-text">5.为什么HDFS文件块设置为128MB？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-HDFS%E7%9A%84%E5%86%99%E6%B5%81%E7%A8%8B"><span class="toc-text">6.HDFS的写流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E8%8A%82%E7%82%B9%E8%B7%9D%E7%A6%BB%E8%AE%A1%E7%AE%97%EF%BC%9F"><span class="toc-text">6.1 节点距离计算？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2Hadoop%E5%89%AF%E6%9C%AC%E8%8A%82%E7%82%B9%E9%80%89%E6%8B%A9%E7%AD%96%E7%95%A5"><span class="toc-text">6.2Hadoop副本节点选择策略</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-HDFS%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B"><span class="toc-text">7.HDFS读数据流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-NameNode%E5%92%8CSecondaryNameNode"><span class="toc-text">8.NameNode和SecondaryNameNode</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-NN%E5%92%8C2NN%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-text">8.1 NN和2NN的工作机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2CheckPoint%E6%97%B6%E9%97%B4%E8%AE%BE%E7%BD%AE"><span class="toc-text">8.2CheckPoint时间设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-3%E9%9B%86%E7%BE%A4%E7%9A%84%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F"><span class="toc-text">8.3集群的安全模式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-DataNode"><span class="toc-text">9.DataNode</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1DataNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-text">9.1DataNode工作机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2DataNode%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7"><span class="toc-text">9.2DataNode检测数据完整性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3DataNode%E6%8E%89%E7%BA%BF%E6%AD%BB%E4%BA%A1%E6%97%B6%E9%97%B4%E7%9A%84%E8%AE%BE%E7%BD%AE"><span class="toc-text">9.3DataNode掉线死亡时间的设置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-%E6%8F%8F%E8%BF%B0%E4%B8%80%E4%B8%8B%E6%89%8B%E5%86%99MR%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%A4%A7%E6%A6%82%E6%B5%81%E7%A8%8B%E5%92%8C%E8%A7%84%E8%8C%83%EF%BC%9F"><span class="toc-text">10.描述一下手写MR程序的大概流程和规范？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0Hadoop%E4%B8%AD%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96%EF%BC%8C%E4%BB%A5%E5%8F%8A%E5%92%8CJava%E5%BA%8F%E5%88%97%E5%8C%96%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-text">11.如何实现Hadoop中的序列化，以及和Java序列化的区别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-%E6%8F%8F%E8%BF%B0%E4%B8%80%E4%B8%8BMR%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91"><span class="toc-text">12.描述一下MR程序的执行逻辑</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-%E6%8F%8F%E8%BF%B0%E4%B8%80%E4%B8%8B%E5%88%87%E7%89%87%E9%80%BB%E8%BE%91"><span class="toc-text">13.描述一下切片逻辑</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14-CombineTextInputFormat%E5%88%87%E7%89%87%E6%9C%BA%E5%88%B6"><span class="toc-text">14.CombineTextInputFormat切片机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#15-MR%E4%B8%AD%E7%9A%84shuffle%E6%9C%BA%E5%88%B6"><span class="toc-text">15.MR中的shuffle机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#15-1%E6%A6%82%E8%BF%B0"><span class="toc-text">15.1概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-2Partion%E5%88%86%E5%8C%BA"><span class="toc-text">15.2Partion分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-3WritableComparable%E6%8E%92%E5%BA%8F"><span class="toc-text">15.3WritableComparable排序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-3Combiner"><span class="toc-text">15.3Combiner</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#16-MapTask%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-text">16.MapTask的工作机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-ReduceTask%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-text">17.ReduceTask的工作机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#18-Map-Join-%E5%92%8CReduce-Join"><span class="toc-text">18.Map Join 和Reduce Join</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#19-Yarn%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-text">19.Yarn的工作机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#20-Hadoop%E4%B8%AD%E7%9A%84%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E5%99%A8"><span class="toc-text">20.Hadoop中的作业调度器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#21-Hadoop%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9"><span class="toc-text">21.Hadoop的数据压缩</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#21-1%E6%A6%82%E8%BF%B0"><span class="toc-text">21.1概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#21-2MR%E6%94%AF%E6%8C%81%E7%9A%84%E5%8E%8B%E7%BC%A9%E7%BC%96%E7%A0%81"><span class="toc-text">21.2MR支持的压缩编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#21-3%E5%8E%8B%E7%BC%A9%E6%96%B9%E5%BC%8F%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-text">21.3压缩方式的选择</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#21-3-1Gzip%E5%8E%8B%E7%BC%A9"><span class="toc-text">21.3.1Gzip压缩</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#21-3-2Bzip2%E5%8E%8B%E7%BC%A9"><span class="toc-text">21.3.2Bzip2压缩</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#21-3-3Lzo%E5%8E%8B%E7%BC%A9"><span class="toc-text">21.3.3Lzo压缩</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#21-3-4-Snappy%E5%8E%8B%E7%BC%A9"><span class="toc-text">21.3.4 Snappy压缩</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#21-4%E5%8E%8B%E7%BC%A9%E4%BD%8D%E7%BD%AE%E9%80%89%E6%8B%A9"><span class="toc-text">21.4压缩位置选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#21-5%E5%8E%8B%E7%BC%A9%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE"><span class="toc-text">21.5压缩参数配置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#22-Hadoop%E4%BC%81%E4%B8%9A%E4%BC%98%E5%8C%96"><span class="toc-text">22.Hadoop企业优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#22-1MapReduce%E8%B7%91%E7%9A%84%E6%85%A2%E7%9A%84%E5%8E%9F%E5%9B%A0"><span class="toc-text">22.1MapReduce跑的慢的原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-2MapReduce%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95"><span class="toc-text">22.2MapReduce优化方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#22-2-1%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5"><span class="toc-text">22.2.1数据输入</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#22-2-2Map%E9%98%B6%E6%AE%B5"><span class="toc-text">22.2.2Map阶段</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#22-2-3-Reduce%E9%98%B6%E6%AE%B5"><span class="toc-text">22.2.3 Reduce阶段</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#22-2-4IO%E9%98%B6%E6%AE%B5"><span class="toc-text">22.2.4IO阶段</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#22-2-5%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E9%97%AE%E9%A2%98"><span class="toc-text">22.2.5数据倾斜问题</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-3%E5%B8%B8%E7%94%A8%E7%9A%84%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0"><span class="toc-text">22.3常用的调优参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-4Hadoop%E5%B0%8F%E6%96%87%E4%BB%B6%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95"><span class="toc-text">22.4Hadoop小文件优化方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#22-4-1Hadoop%E5%B0%8F%E6%96%87%E4%BB%B6%E5%BC%8A%E7%AB%AF"><span class="toc-text">22.4.1Hadoop小文件弊端</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#22-4-2Hadoop%E5%B0%8F%E6%96%87%E4%BB%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95"><span class="toc-text">22.4.2Hadoop小文件解决方法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#23-Hadoop3-x%E7%9A%84%E6%96%B0%E7%89%B9%E6%80%A7"><span class="toc-text">23.Hadoop3.x的新特性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#23-1%E5%A4%9ANN%E7%9A%84HA%E6%9E%B6%E6%9E%84"><span class="toc-text">23.1多NN的HA架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#23-2%E7%BA%A0%E5%88%A0%E7%A0%81"><span class="toc-text">23.2纠删码</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#24-Hadoop-HA%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="toc-text">24.Hadoop HA高可用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#24-1%E6%A6%82%E8%BF%B0"><span class="toc-text">24.1概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#24-2%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-text">24.2工作原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#24-3HDFS-HA%E8%87%AA%E5%8A%A8%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-text">24.3HDFS-HA自动故障转移工作机制</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/09/06/Spark/Spark%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83/" title="Spark运行环境"><img src="/../image/bg.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark运行环境"/></a><div class="content"><a class="title" href="/2022/09/06/Spark/Spark%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83/" title="Spark运行环境">Spark运行环境</a><time datetime="2022-09-06T09:12:20.417Z" title="发表于 2022-09-06 17:12:20">2022-09-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/05/Spark/spark_wordcount/" title="Spark为什么要学"><img src="/../image/bg.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark为什么要学"/></a><div class="content"><a class="title" href="/2022/09/05/Spark/spark_wordcount/" title="Spark为什么要学">Spark为什么要学</a><time datetime="2022-09-05T14:41:18.493Z" title="发表于 2022-09-05 22:41:18">2022-09-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/03/scala/scala%E7%AE%80%E4%BB%8B/" title="Scala概述"><img src="/../image/bg.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Scala概述"/></a><div class="content"><a class="title" href="/2022/09/03/scala/scala%E7%AE%80%E4%BB%8B/" title="Scala概述">Scala概述</a><time datetime="2022-09-03T01:41:36.267Z" title="发表于 2022-09-03 09:41:36">2022-09-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/02/Hbase/Hbase%E6%A6%82%E5%BF%B5/" title="HBase概述"><img src="/../image/bg.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HBase概述"/></a><div class="content"><a class="title" href="/2022/09/02/Hbase/Hbase%E6%A6%82%E5%BF%B5/" title="HBase概述">HBase概述</a><time datetime="2022-09-02T01:50:33.472Z" title="发表于 2022-09-02 09:50:33">2022-09-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/01/Kafka/Kafka%E9%9D%A2%E8%AF%95%E9%A2%98/" title="Kafka面试题总结"><img src="/../image/bg.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Kafka面试题总结"/></a><div class="content"><a class="title" href="/2022/09/01/Kafka/Kafka%E9%9D%A2%E8%AF%95%E9%A2%98/" title="Kafka面试题总结">Kafka面试题总结</a><time datetime="2022-09-01T11:52:47.258Z" title="发表于 2022-09-01 19:52:47">2022-09-01</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/../image/bg.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 <i style="color:#FF6A6A;animation: announ_animation 0.8s linear infinite;" class="fa fa-heartbeat"></i> Xiang Liu</div><div class="footer_custom_text">兽人永不为奴!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script src="https://gcore.jsdelivr.net/gh/xiabo2/CDN@latest/fishes.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>